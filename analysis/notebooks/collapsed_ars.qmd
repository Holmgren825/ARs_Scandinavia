---
title: Collapsed ARs
author: Erik Holmgren
format:
  html:
    code-fold: show
    toc: true
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.16.4
  kernelspec:
    display_name: ar_ident
    language: python
    name: ar_ident
---

```{python}
%load_ext autoreload
```

```{python}
%autoreload 2
```

```{python}
import re
from glob import glob
from itertools import combinations
from pathlib import Path

import cf_xarray
import dask.array as da
import numpy as np
import pandas as pd
import proplot as pplt
import scipy
import xarray as xr
from ar_identify.metrics import spatial_jaccard_score
from ar_scandinavia.pca_utils import combine_artmip_pca_results
from ar_scandinavia.utils import compute_ar_pr_values_collapsed, subsel_ds
from cartopy import crs as ccrs
from dask_ml.cluster import KMeans
from distributed.client import Client
from tqdm.autonotebook import tqdm
from xr_utils.coordinates import conv_lon_to_180
```

```{python}
pplt.rc["font.size"] = 7
```

```{python}
LAT_SLICE = (50, 74)
LON_SLICE = (-10, 45)
```

```{python}
client = Client()
```

```{python}
precip_path = "/data/era5/total_precipitation/total_precipitation-*6h.zarr/"
precip_ds = xr.open_mfdataset(precip_path, engine="zarr")
```

```{python}
precip_ds = precip_ds.cf.sel(time=slice("1980", "2019"))
```

```{python}
precip_ds = subsel_ds(precip_ds, LAT_SLICE, LON_SLICE)
```

```{python}
xr.open_zarr(
    "/data/atmospheric_rivers/artmip/ERA5.ar.GuanWaliser_v2.1hr/ERA5.ar_ids.GuanWaliser_v2.6hr.19790101-20191231_scandinavia.zarr/"
)
```

```{python}
# NOTE: also convert to mm.
ann_avg_precip_ds = precip_ds.tp.groupby("valid_time.year").sum().mean("year").load() * 1e3
```

# Check relevant number of clusters.

```{python}
from sklearn.metrics import silhouette_score
```

```{python}
data = test.ar_tracked_id.data
data = data.reshape(data.shape[0], -1)
data = data.persist()

intertia_scores = []
silhouette_scores = []
for n_clusters in tqdm(range(2, 10)):
    kmeans = KMeans(n_clusters=n_clusters)
    kmeans.fit(data)
    intertia_scores.append(kmeans.inertia_)
    labels = kmeans.predict(data)
    silhouette_scores.append(silhouette_score(data, labels))
```

```{python}
fig, axs = pplt.subplots(ncols=2, sharey=False)
axs[0].plot(range(2, 10), intertia_scores)
axs[0].format(ylabel="WCSS")
axs[1].plot(range(2, 10), silhouette_scores)
axs[1].format(ylabel="Silhouette score")
axs.format(xlabel="N clusters", suptitle="N cluster evaluation [Mundhenk]")
```

```{python}
fig.savefig("../../figures/n_cluster_eval.svg")
```

# Precipitation during AR time steps

## Ensemble average AR timestep and year

```{python}
import os
```

```{python}
BASE_PATH = "/data/projects/atmo_rivers_scandinavia/"
ARDT_NAMES = ["Mundhenk_v3", "Reid500", "GuanWaliser_v2", "TempestLR"]
```

```{python}
label_dict = {
    "Mundhenk_v3": {
        0: 0,
        1: 1,
        2: 2,
        3: 3,
    },
    "GuanWaliser_v2": {
        0: 3,
        1: 1,
        2: 0,
        3: 2,
    },
    "TempestLR": {
        0: 0,
        1: 3,
        2: 3,
        3: 2,
    },
    "Reid500": {
        0: 0,
        1: 3,
        2: 3,
        3: 3,
    },
}


def get_cluster_timesteps(
    cluster_ds: xr.Dataset, precip_ds: xr.Dataset, ardt_name: str
) -> xr.Dataset:
    """Get a dataset with all timesteps for the clusters in cluster_ds."""
    curr_times = np.asarray(
        list(
            map(
                lambda x: x[-23:].split("-"),
                cluster_ds.sample_id.values,
            )
        )
    )
    labels = cluster_ds.labels.load()
    # NOTE: Here we just get the timesteps.
    ar_pr_timesteps = []
    padded_labels = []
    for i, time in enumerate(curr_times):
        pr_ts = precip_ds.tp.cf.sel(
            time=slice(time[0], time[1]),
        ).cf["time"]
        curr_label = labels.isel(sample_id=[i]).values[0]
        # NOTE: Here we re-map the labels to common geogrpahical feature.
        curr_label = label_dict[ardt_name][curr_label]
        padded_labels.extend([curr_label] * pr_ts.shape[0])
        ar_pr_timesteps.append(pr_ts)

    ar_pr_timesteps_ds = xr.concat(ar_pr_timesteps, dim="valid_time")
    padded_labels = np.asarray(padded_labels)
    assert padded_labels.shape[0] == ar_pr_timesteps_ds.shape[0]

    ar_pr_timesteps_ds = xr.DataArray(
        padded_labels, coords={"valid_time": ar_pr_timesteps_ds.valid_time}
    )
    return ar_pr_timesteps_ds
```

First we get the timesteps for the differnt ARDTs

```{python}
ar_ts_ens = []
for ardt_name in tqdm(ARDT_NAMES):
    cluster_path = os.path.join(
        BASE_PATH,
        f"ERA5.{ardt_name}",
        f"ERA5.{ardt_name}.collapsed.cluster_labels.zarr",
    )
    cluster_ds = xr.open_zarr(cluster_path)

    ar_ts_ds = get_cluster_timesteps(cluster_ds, precip_ds, ardt_name)
    ar_ts_ds = ar_ts_ds.assign_coords({"ardt": ardt_name})
    ar_ts_ens.append(ar_ts_ds)
ar_ts_ens = xr.concat(ar_ts_ens, dim="valid_time")
```

Then we can select the precipitation timesteps for each of them:
At this points, we don't really need to care about the ensemble members, we can just pile all of it into a single large 1d array?
- For the histograms yes, but not for the maps? 
- But we can remove the time coordinate for now, but it would be nice to keep the groupby functionality.

```{python}
ar_precip_ens = precip_ds.cf.sel(time=ar_ts_ens.valid_time)
n_ar_precip_ens = precip_ds.where(
    ~precip_ds.cf["time"].isin(ar_ts_ens.valid_time), drop=True
)
```

### Annual average

```{python}
n_ar_ann_avg = n_ar_precip_ens.cf.groupby("time.year").sum().mean("year").tp.compute()
ar_ann_avg = ar_precip_ens.cf.groupby("time.year").sum().mean("year").tp.compute() / 4
```

```{python}
fig, axs = pplt.subplots(
    figwidth="8.3cm",
    nrows=2,
    proj=2 * ["nsper"],
    proj_kw={"lon_0": 14, "lat_0": 65},
    abc=True,
)
# vmax = max(n_ar_ann_avg.max().values, ar_ann_avg.max().values)
cm = ar_ann_avg.plot(
    ax=axs[0], vmin=0, cmap="oslor_r", add_colorbar=False, rasterized=True
)
# cm = ar_ann_avg.plot(ax=axs[1], vmin=0, vmax=vmax, cmap="oslor_r", add_colorbar=False)
axs[0].colorbar(cm, label="Total annual average\nprecipitation [m]")

(ar_ann_avg / ann_avg_precip_ds * 100).plot(
    ax=axs[1],
    cbar_kwargs={"label": "Total precipitation\nfraction [%]"},
    rasterized=True,
)

axs.format(
    coast=True,
    reso="med",
    lonlim=LON_SLICE,
    latlim=LAT_SLICE,
    title="",
    rowlabels=["Total AR precip.", "AR precip. fraction"],
    suptitle="Annual average precipitation\nduring ARs [Ensemble averge]",
    abcloc="ul",
    abcbbox=True,
)
```

```{python}
fig.savefig("../../figures/ann_avg_precip_ar_ens.svg")
```

### Average timestep

Get histograms

Select only unique time steps, no doubles.

```{python}
ar_precip_ens_unique = precip_ds.sel(valid_time=np.unique(ar_precip_ens.valid_time))
```

```{python}
# Convert to mm/h
ar_precip_mh = ar_precip_ens * 1e3 / 6
ar_precip_mh_unique = ar_precip_ens_unique * 1e3 / 6
n_ar_precip_mh = n_ar_precip_ens * 1e3 / 6
```

```{python}
weights = np.cos(np.deg2rad(ar_precip_mh_unique.latitude))

# Mean
ar_precip_hist = ar_precip_mh_unique.weighted(weights).mean(["latitude", "longitude"])
n_ar_precip_hist = n_ar_precip_mh.weighted(weights).mean(["latitude", "longitude"])

# Max (0.75 quantile)
ar_precip_hist_max = ar_precip_mh_unique.quantile(0.75, ["latitude", "longitude"])
n_ar_precip_hist_max = n_ar_precip_mh.quantile(0.75, ["latitude", "longitude"])
```

```{python}
bin_max = np.round(
    max(
        ar_precip_hist.tp.max().compute(),
        n_ar_precip_hist.tp.max().compute(),
        ar_precip_hist_max.tp.max().compute(),
        n_ar_precip_hist_max.tp.max().compute(),
    ),
    decimals=2,
)
```

```{python}
hist_bin_range = (0, bin_max.values)
n_bins = 15
```

```{python}
hist_ar, bins = da.histogram(
    ar_precip_hist.tp.data, range=hist_bin_range, bins=n_bins, density=True
)
hist_ar = hist_ar.compute()
```

```{python}
hist_n_ar, bins = da.histogram(
    n_ar_precip_hist.tp.data, range=hist_bin_range, bins=n_bins, density=True
)
hist_n_ar = hist_n_ar.compute()
```

Histograms for the 0.75 qtile.

```{python}
qtile_hist_ar, bins = da.histogram(
    ar_precip_hist_max.tp.data, range=hist_bin_range, bins=n_bins, density=True
)
qtile_hist_ar = qtile_hist_ar.compute()
```

```{python}
qtile_hist_n_ar, bins = da.histogram(
    n_ar_precip_hist_max.tp.data, range=hist_bin_range, bins=n_bins, density=True
)
qtile_hist_n_ar = qtile_hist_n_ar.compute()
```

```{python}
# non_ar_precip_sum_ds = non_ar_precip_ds.cf.sum("time").compute()
```

```{python}
# mean
ar_med = ar_precip_mh.cf.mean("valid_time").compute()
n_ar_med = n_ar_precip_mh.cf.mean("valid_time").compute()
# std
# ar_std = ar_precip_ens.cf.std("valid_time").compute() * 1000
# n_ar_std = n_ar_precip_ens.cf.std("valid_time").compute() * 1000
```

```{python}
fig, axs = pplt.subplots(
    figwidth="8.3cm",
    #figheight="12cm",
    nrows=3,
    proj=2 * ["nsper"] + [None],
    proj_kw={"lon_0": 14, "lat_0": 65},
    sharey=False,
    sharex=False,
    abc=True,
)

qtile = 0.95
vmax = max(ar_med.tp.quantile(qtile).values, n_ar_med.tp.quantile(qtile).values)

cmap = pplt.Colormap("oslo_r", right=0.8)

pr_cm = (n_ar_med.tp).plot(
    ax=axs[0], cmap=cmap, vmin=0, vmax=vmax, add_colorbar=False, rasterized=True
)

pr_cm = (ar_med.tp).plot(
    ax=axs[1], cmap=cmap, vmin=0, vmax=vmax, add_colorbar=False, rasterized=True
)
pr_cbar = fig.colorbar(
    pr_cm, loc="right",rows=(1, 2), length=0.7, label="Precipitation [mm/h]", extend="max"
)

axs[2].stairs(hist_ar, bins, label="AR [Avg.]", color="C0")

axs[2].stairs(hist_n_ar, bins, label="No AR [Avg.]", color="C1")

axs[2].stairs(qtile_hist_ar, bins, label="— [3rd qtile]", color="C0", ls="--")
axs[2].stairs(qtile_hist_n_ar, bins, label="— [3rd qtile]", color="C1", ls="--")

axs[2].format(
    # yscale="log",
    xlabel="Precipitation [mm/h]",
    ylabel="Density",
    ytickloc="l",
    ylabelloc="l",
    title="Histogram of 1 hour precipitation"
)
axs[2].legend(loc="ur", ncols=2)
axs[:2].format(
    title=""
)
axs.format(
    coast=True,
    reso="med",
    lonlim=LON_SLICE,
    latlim=LAT_SLICE,
    #title="",
    rowlabels=["Non-AR", "AR", ""],
    suptitle="Average timestep precipitation\n[Ensemble average]",
    abcloc="ul",
    abcbbox=True,
)
```

```{python}
fig.savefig("../../figures/avg_precip_timestep_ar_ens.svg")
```

### Time step avg/std.

```{python}
# mean
ar_std = ar_precip_mh.groupby("ardt").mean().std("ardt").compute()
```

```{python}
fig, axs = pplt.subplots(
    figwidth="8.3cm",
    #figheight="12cm",
    nrows=2,
    proj=2 * ["nsper"],
    proj_kw={"lon_0": 14, "lat_0": 65},
    sharey=False,
    sharex=False,
    abc=True,
)


cmap = pplt.Colormap("oslo_r", right=0.8)
qtile = 0.95
#vmax = max(ar_med.tp.quantile(qtile).values, ar_std.tp.quantile(qtile).values)
pr_cm = (ar_med.tp).plot(
    ax=axs[0], cmap=cmap, vmin=0, add_colorbar=False, rasterized=True
)
pr_cbar = axs[0].colorbar(
    pr_cm, loc="right", label="Precipitation [mm/h]"
)

pr_cm = (ar_std.tp).plot(
    ax=axs[1], cmap=cmap, vmin=0, add_colorbar=False, rasterized=True
)
pr_cbar = axs[1].colorbar(
    pr_cm, loc="right", label="Precipitation [mm/h]"
)

axs.format(
    coast=True,
    reso="med",
    lonlim=LON_SLICE,
    latlim=LAT_SLICE,
    title="",
    rowlabels=["Avg", "Std.",],
    suptitle="Time step precipitation [Ensemble]",
    abcloc="ul",
    abcbbox=True,
)
```

```{python}
fig.savefig("../../figures/avg_std_precip_timestep_ar_ens.svg")
```

### Cluster ensemble

Could we have a start and end time coordinate for the samples? In order to be able to index by time?

```{python}
ar_precip_ens = ar_precip_ens.assign_coords({"label": ar_ts_ens})
```

```{python}
# NOTE: Need to divide by 4 since we have 4 ARDTs?
ar_precip_ens_avg = (
    ar_precip_ens.groupby(["label", "valid_time.year"]).sum().mean("year").load() / 4
) * 1e3
ar_precip_ens_avg_ts = ar_precip_ens.groupby(["label"]).mean().load()
```

```{python}
def remap_labels(labels: da.array, label_dict: dict) -> da.array:
    return labels.map_blocks(
        lambda x: np.vectorize(label_dict.get)(x),
        dtype=int,
    )
```

```{python}
ar_ens_ds = []
for ardt_name in tqdm(ARDT_NAMES):
    ar_path = os.path.join(
        BASE_PATH,
        f"ERA5.{ardt_name}",
        f"ERA5.{ardt_name}.scand_ars.collapsed.1980-2019.zarr",
    )
    label_path = os.path.join(
        BASE_PATH,
        f"ERA5.{ardt_name}",
        f"ERA5.{ardt_name}.collapsed.cluster_labels.zarr",
    )
    ar_ds = xr.open_zarr(ar_path)
    label_ds = xr.open_zarr(label_path)
    ar_ds = subsel_ds(ar_ds, LAT_SLICE, LON_SLICE)

    curr_times = np.asarray(
        list(
            map(
                lambda x: x[-23:].split("-"),
                ar_ds.sample_id.values,
            )
        )
    )
    start_times = pd.to_datetime(curr_times[:, 0], format="%Y%m%dT%H")
    labels = remap_labels(label_ds.labels.data, label_dict[ardt_name])

    ar_ds = ar_ds.assign_coords({"start_time": ("sample_id", start_times)})
    ar_ds = ar_ds.assign_coords({"label": ("sample_id", labels)})

    ar_ens_ds.append(ar_ds)

ar_ens_ds = xr.concat(ar_ens_ds, dim="ardt")
```

```{python}
grouped_ars = ar_ens_ds.groupby(["start_time.year", "label"]).sum().mean("year")
```

```{python}
grouped_ars = grouped_ars.load()
```

#### Total precip fraction

```{python}
fig, axs = pplt.subplots(
    figwidth="12cm",
    nrows=4,
    ncols=2,
    proj=4 * 2 * ["nsper"],
    proj_kw={"lon_0": 14, "lat_0": 65},
    sharey=False,
    sharex=False,
    abc=True,
)
vmax = ar_precip_ens_avg.tp.max().values
cmap = pplt.Colormap("oslo_r", right=0.8)
for i in range(4):
    cm = (grouped_ars.isel(label=i).ar_tracked_id / 1464 * 100).plot(
        ax=axs[i, 0],
        vmin=0,
        rasterized=True,
        add_colorbar=False,
    )
    axs[i, 0].colorbar(cm, label="Frequncy [%]", width=0.15)
    curr_tp = ar_precip_ens_avg.isel(label=i).tp
    cm = (curr_tp / ann_avg_precip_ds * 100).plot(
        ax=axs[i, 1],
        vmin=0,
        # vmax=16,
        cmap=cmap,
        rasterized=True,
        add_colorbar=False,
        # cbar_kwargs={"label": "Total precipitation\nfraction [%]"},
    )
    axs[i, 1].colorbar(cm, label="Total precipitation\nfraction [%]", width=0.15)


axs.format(
    coast=True,
    reso="med",
    lonlim=LON_SLICE,
    latlim=LAT_SLICE,
    title="",
    abcloc="ul",
    abcbbox=True,
    rowlabels=[f"Cluster {i}" for i in range(1, 5)],
    collabels=["AR Frequency", "Total precipitation fraction"],
    suptitle="Ensemble average AR clusters",
)
```

```{python}
fig.savefig("../../figures/ann_avg_precip_ar_ens_per_cluster.svg")
```

#### Total precip fraction std

```{python}
ar_precip_cluster_std = ar_precip_ens.groupby(["ardt", "label", "valid_time.year"]).sum().mean("year").std("ardt") * 1e3
```

```{python}
ar_precip_cluster_std = ar_precip_cluster_std.load()
```

```{python}
freq_cluster_std = ar_ens_ds.groupby(["ardt", "label", "start_time.year"]).sum().mean("year").std("ardt").load()
```

```{python}
fig, axs = pplt.subplots(
    figwidth="12cm",
    nrows=4,
    ncols=2,
    proj=4 * 2 * ["nsper"],
    proj_kw={"lon_0": 14, "lat_0": 65},
    sharey=False,
    sharex=False,
    abc=True,
)
vmax = ar_precip_ens_avg.tp.max().values
cmap = pplt.Colormap("oslo_r", right=0.8)
for i in range(4):
    cm = (freq_cluster_std.isel(label=i).ar_tracked_id / 1464 * 100).plot(
        ax=axs[i, 0],
        vmin=0,
        rasterized=True,
        add_colorbar=False,
    )
    axs[i, 0].colorbar(cm, label="Frequncy [%]", width=0.15)
    curr_tp = ar_precip_cluster_std.isel(label=i).tp
    cm = (curr_tp / ann_avg_precip_ds * 100).plot(
        ax=axs[i, 1],
        vmin=0,
        # vmax=16,
        cmap=cmap,
        rasterized=True,
        add_colorbar=False,
        # cbar_kwargs={"label": "Total precipitation\nfraction [%]"},
    )
    axs[i, 1].colorbar(cm, label="Total precipitation\nfraction [%]", width=0.15)


axs.format(
    coast=True,
    reso="med",
    lonlim=LON_SLICE,
    latlim=LAT_SLICE,
    title="",
    abcloc="ul",
    abcbbox=True,
    rowlabels=[f"Cluster {i}" for i in range(1, 5)],
    collabels=["AR Frequency", "Total precipitation fraction"],
    suptitle="AR clusters ensemble std.",
)
```

```{python}
fig.savefig("../../figures/ann_std_precip_ar_ens_per_cluster.svg")
```

#### Average timestep

```{python}
fig, axs = pplt.subplots(
    figwidth="12cm",
    nrows=4,
    ncols=2,
    proj=4 * 2 * ["nsper"],
    proj_kw={"lon_0": 14, "lat_0": 65},
    sharey=False,
    sharex=False,
    abc=True,
)
vmax = ar_precip_ens_avg.tp.max().values
for i in range(4):
    cm = (grouped_ars.isel(label=i).ar_tracked_id / 1464 * 100).plot(
        ax=axs[i, 0],
        vmin=0,
        rasterized=True,
        add_colorbar=False,
        # cbar_kwargs={"label": "Frequency [%]"},
    )
    axs[i, 0].colorbar(cm, label="Frequncy [%]", width=0.15)

    cm = (ar_precip_ens_avg_ts.isel(label=i).tp * 1000).plot(
        ax=axs[i, 1], vmin=0, cmap="oslo_r", rasterized=True, add_colorbar=False
    )
    axs[i, 1].colorbar(cm, label="Total precipitation\n [mm]", width=0.15)


axs.format(
    coast=True,
    reso="med",
    lonlim=LON_SLICE,
    latlim=LAT_SLICE,
    title="",
    abcloc="ul",
    abcbbox=True,
    rowlabels=[f"Cluster {i}" for i in range(1, 5)],
    collabels=["AR Frequency", "Timestep avg. total precipitation"],
    suptitle="Ensemble average AR clusters",
)
```

```{python}
fig.savefig("../../figures/avg_precip_ar_timestep_ens_per_cluster.svg")
```

#### Clusters grouped by season

```{python}
ar_ens_ds = ar_ens_ds.load()
```

```{python}
season_grouped_ars = (
    ar_ens_ds.groupby(["start_time.season", "start_time.year", "label"])
    .sum()
    .mean("year")
)
season_grouped_ars
```

```{python}
season_grouped_ars = season_grouped_ars.isel(season=slice(0, -1))
```

Get the number of samples for each season, on average.

```{python}
season_samples = {}
for key, val in (
    precip_ds.sel(valid_time="1981").groupby("valid_time.season").groups.items()
):
    season_samples[key] = len(val)
```

```{python}
season_samples
```

Pre-compute the frequencies.

```{python}
freqs = (
    season_grouped_ars
    / np.asarray(list(season_samples.values())).reshape((1, 1, -1, 1))
    / 4
    * 100
)
```

```{python}
season_order = ["DJF", "MAM", "JJA", "SON"]
nrows = 4
ncols = 4
fig, axs = pplt.subplots(
    figwidth="12cm",
    nrows=nrows,
    ncols=ncols,
    proj=nrows * ncols * ["nsper"],
    proj_kw={"lon_0": 14, "lat_0": 65},
    sharey=False,
    sharex=False,
    abc=True,
)
for i in range(nrows):
    vmax = freqs.isel(label=i).ar_tracked_id.max().values
    for j, season in enumerate(season_order):
        cm = (
            freqs.isel(label=i)
            .sel(season=season)
            .ar_tracked_id.plot(
                ax=axs[i, j], rasterized=True, vmin=0, vmax=vmax, add_colorbar=False
            )
        )
    axs[i, -1].colorbar(cm, label="Frequency [%]", width=0.1)

axs.format(
    coast=True,
    reso="med",
    lonlim=LON_SLICE,
    latlim=LAT_SLICE,
    title="",
    abcloc="ul",
    abcbbox=True,
    rowlabels=[f"Cluster {i}" for i in range(1, 5)],
    collabels=season_order,
    suptitle="Ensemble average seasonal AR frequencies",
)
```

```{python}
fig.savefig("../../figures/ens_avg_seasonal_ar_clusters.svg")
```

```{python}
Standard deviation
```

```{python}
ar_ens_ds
```

```{python}
season_groups_std = ar_ens_ds.groupby(["ardt", "label", "start_time.season", "start_time.year"]).sum().mean("year").std("ardt")
```

```{python}
freqs = (
    season_groups_std
    / np.asarray(list(season_samples.values())).reshape((1, 1, -1, 1))
    * 100
)
```

```{python}
season_order = ["DJF", "MAM", "JJA", "SON"]
nrows = 4
ncols = 4
fig, axs = pplt.subplots(
    figwidth="12cm",
    nrows=nrows,
    ncols=ncols,
    proj=nrows * ncols * ["nsper"],
    proj_kw={"lon_0": 14, "lat_0": 65},
    sharey=False,
    sharex=False,
    abc=True,
)
for i in range(nrows):
    vmax = freqs.isel(label=i).ar_tracked_id.max().values
    for j, season in enumerate(season_order):
        cm = (
            freqs.isel(label=i)
            .sel(season=season)
            .ar_tracked_id.plot(
                ax=axs[i, j], rasterized=True, vmin=0, vmax=vmax, add_colorbar=False
            )
        )
    axs[i, -1].colorbar(cm, label="Frequency [%]", width=0.1)

axs.format(
    coast=True,
    reso="med",
    lonlim=LON_SLICE,
    latlim=LAT_SLICE,
    title="",
    abcloc="ul",
    abcbbox=True,
    rowlabels=[f"Cluster {i}" for i in range(1, 5)],
    collabels=season_order,
    suptitle="Seasonal AR frequencies ensemble std.",
)
```

```{python}
fig.savefig("../../figures/ens_std_seasonal_ar_clusters.svg")
```

#### Cluster grouped by NAO

```{python}
def prepare_nao_ds(path: str | None = None) -> pd.Series:
    """Prepare NAO dataframe."""
    if path is None:
        path = Path(__file__).parent / "../etc/norm_daily_nao_index_1950_2024.txt"

    nao_df: pd.DataFrame = pd.read_csv(
        filepath_or_buffer=path,
        sep=r"\s+",
        header=None,
        names=["year", "month", "day", "nao"],
        dtype={"year": str, "month": str, "day": str, "nao": float},
        na_values="-99.0",
    )
    nao_df["time"] = pd.to_datetime(
        nao_df["year"] + "-" + nao_df["month"] + "-" + nao_df["day"]
    )
    nao_df.index = pd.Index(nao_df.time)
    nao_series = nao_df["nao"]
    nao_series = nao_series.interpolate()

    # Upsample to 6 hourly for convenience with era5 data.
    nao_series = nao_series.resample("6h").ffill()

    # first_timestep = ar_ds.time[:1].to_numpy()[0]
    # last_timestep = ar_ds.time[-1:].to_numpy()[0]

    # # What year do we need?
    # nao_series = nao_series.loc[first_timestep:last_timestep]

    return nao_series


def get_nao_bins(nao_series: pd.Series, midpoint_qtile: float = 0.5) -> np.ndarray:
    """Generate NAO bins with roughly equal number of samples on either side of 0."""
    # TODO: Don't hard code midpoint.
    bins = np.quantile(
        nao_series,
        [
            0,
            midpoint_qtile / 2,
            midpoint_qtile,
            midpoint_qtile + (1 - midpoint_qtile) / 2,
            1,
        ],
    )
    return bins
```

```{python}
nao_series = prepare_nao_ds(path="../etc/norm_daily_nao_index_1950_2024.txt")
nao_series = nao_series.loc["1980":"2019"]
nao_da = xr.DataArray(nao_series)
# nao_bins = get_nao_bins(nao_series)
nao_bins = (-3.5, -0.5, 0, 0.5, 3.5)

hist, bins = np.histogram(nao_series, nao_bins)
```

```{python}
hist
```

Select the nao values for dates when we have ARs

```{python}
ar_nao_values = nao_da.sel(time=ar_ens_ds.start_time, method="nearest")
ar_nao_values = ar_nao_values.where(~ar_nao_values.label.isnull())
```

and assign them as coordinate to the ar ensemble

```{python}
ar_ens_ds = ar_ens_ds.assign_coords({"nao": ar_nao_values})
```

Groupby both nao and the cluster label.

```{python}
from xarray.groupers import BinGrouper, TimeResampler, UniqueGrouper
```

```{python}
ar_nao_groups = ar_ens_ds.groupby(nao=BinGrouper(nao_bins), label=UniqueGrouper()).sum()
```

```{python}
# Reshape for broadcasting
nao_counts = hist.reshape((1, 1, -1, 1))
```

Calculate the frequencies

```{python}
freqs = ar_nao_groups / nao_counts / 4 * 100
```

```{python}
nrows = 4
ncols = 4
fig, axs = pplt.subplots(
    figwidth="12cm",
    nrows=nrows,
    ncols=ncols,
    proj=nrows * ncols * ["nsper"],
    proj_kw={"lon_0": 14, "lat_0": 65},
    sharey=False,
    sharex=False,
    abc=True,
)
for i in range(nrows):
    vmax = freqs.isel(label=i).ar_tracked_id.max().values
    for j in range(4):
        cm = freqs.isel(label=i, nao_bins=j).ar_tracked_id.plot(
            ax=axs[i, j], rasterized=True, vmin=0, vmax=vmax, add_colorbar=False
        )
    axs[i, -1].colorbar(cm, label="Frequency [%]", width=0.1)

axs.format(
    coast=True,
    reso="med",
    lonlim=LON_SLICE,
    latlim=LAT_SLICE,
    title="",
    abcloc="ul",
    abcbbox=True,
    rowlabels=[f"Cluster {i}" for i in range(1, 5)],
    collabels=[f"{bin}" for bin in freqs.nao_bins.values],
    suptitle="NAO-grouped AR frequencies ensemble averages",
)
```

```{python}
fig.savefig("../../figures/ens_avg_nao_ar_clusters.svg")
```

```{python}
ar_nao_std_groups = ar_ens_ds.groupby(nao=BinGrouper(nao_bins), label=UniqueGrouper(), ardt=UniqueGrouper()).sum().std("ardt")
```

```{python}
freqs = ar_nao_std_groups / nao_counts * 100
```

```{python}
nrows = 4
ncols = 4
fig, axs = pplt.subplots(
    figwidth="12cm",
    nrows=nrows,
    ncols=ncols,
    proj=nrows * ncols * ["nsper"],
    proj_kw={"lon_0": 14, "lat_0": 65},
    sharey=False,
    sharex=False,
    abc=True,
)
for i in range(nrows):
    vmax = freqs.isel(label=i).ar_tracked_id.max().values
    for j in range(4):
        cm = freqs.isel(label=i, nao_bins=j).ar_tracked_id.plot(
            ax=axs[i, j], rasterized=True, vmin=0, vmax=vmax, add_colorbar=False
        )
    axs[i, -1].colorbar(cm, label="Frequency [%]", width=0.1)

axs.format(
    coast=True,
    reso="med",
    lonlim=LON_SLICE,
    latlim=LAT_SLICE,
    title="",
    abcloc="ul",
    abcbbox=True,
    rowlabels=[f"Cluster {i}" for i in range(1, 5)],
    collabels=[f"{bin}" for bin in freqs.nao_bins.values],
    suptitle="NAO-grouped AR frequencies ensemble std.",
)
```

```{python}
fig.savefig("../../figures/ens_std_nao_ar_clusters.svg")
```

